{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleNNGradualFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeKkwHtzrOG0o8fA0P8bnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruygonzalez/CS155KaggleCompetition1/blob/master/KaggleNeuralNetFunnelwithEarlyStopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rORdsNRQMvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElxlVR940dPU",
        "colab_type": "text"
      },
      "source": [
        "## Import and Process the Data\n",
        "First, we import the data into dataframes and change the data a little bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E24kVNy6zBJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"./train.csv\")\n",
        "test_df = pd.read_csv(\"./test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FTLhctb0Yxl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl1BAwS-zonS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_dataframe(df):\n",
        "  '''Given the training or test data frame, process it to\n",
        "     remove the NaN values'''\n",
        "\n",
        "  # Add new columns!\n",
        "  df[\"bid_ask_spread1\"] = df[\"bid1\"].subtract(df[\"ask1\"])\n",
        "  df[\"bid_ask_spread2\"] = df[\"bid2\"].subtract(df[\"ask2\"])\n",
        "  df[\"bid_ask_spread3\"] = df[\"bid3\"].subtract(df[\"ask3\"])\n",
        "  df[\"bid_ask_spread4\"] = df[\"bid4\"].subtract(df[\"ask4\"])\n",
        "  df[\"bid_ask_spread5\"] = df[\"bid5\"].subtract(df[\"ask5\"])\n",
        "\n",
        "  df[\"bid_ask_div1\"] = df[\"bid1\"].div(df[\"ask1\"])\n",
        "  df[\"bid_ask_div2\"] = df[\"bid2\"].div(df[\"ask2\"])\n",
        "  df[\"bid_ask_div3\"] = df[\"bid3\"].div(df[\"ask3\"])\n",
        "  df[\"bid_ask_div4\"] = df[\"bid4\"].div(df[\"ask4\"])\n",
        "  df[\"bid_ask_div5\"] = df[\"bid5\"].div(df[\"ask5\"])\n",
        "\n",
        "  df[\"mid_price2\"] = (df[\"bid2\"].add(df[\"ask2\"])).div(2)\n",
        "  df[\"mid_price3\"] = (df[\"bid3\"].add(df[\"ask3\"])).div(2)\n",
        "  df[\"mid_price4\"] = (df[\"bid4\"].add(df[\"ask4\"])).div(2)\n",
        "  df[\"mid_price5\"] = (df[\"bid5\"].add(df[\"ask5\"])).div(2)\n",
        "\n",
        "  df[\"last_div_mid\"] = df[\"last_price\"].div(df[\"mid\"])\n",
        "  df[\"last_div_mid2\"] = df[\"last_price\"].div(df[\"mid_price2\"])\n",
        "  df[\"last_div_mid3\"] = df[\"last_price\"].div(df[\"mid_price3\"])\n",
        "  df[\"last_div_mid4\"] = df[\"last_price\"].div(df[\"mid_price4\"])\n",
        "  df[\"last_div_mid5\"] = df[\"last_price\"].div(df[\"mid_price5\"])\n",
        "\n",
        "  df[\"transact_div_mid\"] = df[\"transacted_qty\"].div(df[\"mid\"])\n",
        "  df[\"transact_div_last\"] = df[\"transacted_qty\"].div(df[\"last_price\"])\n",
        "\n",
        "  df[\"bid1_vs_last\"] = df[\"bid1\"].div(df[\"last_price\"])\n",
        "  df[\"bid2_vs_last\"] = df[\"bid2\"].div(df[\"last_price\"])\n",
        "  df[\"bid1vol_vs_last\"] = df[\"bid1vol\"].div(df[\"last_price\"])\n",
        "  df[\"bid2vol_vs_last\"] = df[\"bid2vol\"].div(df[\"last_price\"])\n",
        "\n",
        "  df[\"bid3_vs_last\"] = df[\"bid3\"].div(df[\"last_price\"])\n",
        "  df[\"bid4_vs_last\"] = df[\"bid4\"].div(df[\"last_price\"])\n",
        "  df[\"bid3vol_vs_last\"] = df[\"bid3vol\"].div(df[\"last_price\"])\n",
        "  df[\"bid4vol_vs_last\"] = df[\"bid4vol\"].div(df[\"last_price\"])\n",
        "  df[\"bid5_vs_last\"] = df[\"bid5\"].div(df[\"last_price\"])\n",
        "  df[\"bid5vol_vs_last\"] = df[\"bid5vol\"].div(df[\"last_price\"])\n",
        "\n",
        "  df[\"ask1_vs_last\"] = df[\"ask1\"].div(df[\"last_price\"])\n",
        "  df[\"ask2_vs_last\"] = df[\"ask2\"].div(df[\"last_price\"])\n",
        "  df[\"ask1vol_vs_last\"] = df[\"ask1vol\"].div(df[\"last_price\"])\n",
        "  df[\"ask2vol_vs_last\"] = df[\"ask2vol\"].div(df[\"last_price\"])\n",
        "\n",
        "  df[\"ask3_vs_last\"] = df[\"ask3\"].div(df[\"last_price\"])\n",
        "  df[\"ask4_vs_last\"] = df[\"ask4\"].div(df[\"last_price\"])\n",
        "  df[\"ask3vol_vs_last\"] = df[\"ask3vol\"].div(df[\"last_price\"])\n",
        "  df[\"ask4vol_vs_last\"] = df[\"ask4vol\"].div(df[\"last_price\"])\n",
        "  df[\"ask5_vs_last\"] = df[\"ask5\"].div(df[\"last_price\"])\n",
        "  df[\"ask5vol_vs_last\"] = df[\"ask5vol\"].div(df[\"last_price\"])\n",
        "\n",
        "  df[\"bid1_vs_mid\"] = df[\"bid1\"].div(df[\"mid\"])\n",
        "  df[\"bid2_vs_mid\"] = df[\"bid2\"].div(df[\"mid\"])\n",
        "  df[\"bid1vol_vs_mid\"] = df[\"bid1vol\"].div(df[\"mid\"])\n",
        "  df[\"bid2vol_vs_mid\"] = df[\"bid2vol\"].div(df[\"mid\"])\n",
        "\n",
        "  df[\"bid3_vs_mid\"] = df[\"bid3\"].div(df[\"mid\"])\n",
        "  df[\"bid4_vs_mid\"] = df[\"bid4\"].div(df[\"mid\"])\n",
        "  df[\"bid3vol_vs_mid\"] = df[\"bid3vol\"].div(df[\"mid\"])\n",
        "  df[\"bid4vol_vs_mid\"] = df[\"bid4vol\"].div(df[\"mid\"])\n",
        "  df[\"bid5_vs_mid\"] = df[\"bid5\"].div(df[\"mid\"])\n",
        "  df[\"bid5vol_vs_mid\"] = df[\"bid5vol\"].div(df[\"mid\"])\n",
        "\n",
        "  df[\"ask1_vs_mid\"] = df[\"ask1\"].div(df[\"mid\"])\n",
        "  df[\"ask2_vs_mid\"] = df[\"ask2\"].div(df[\"mid\"])\n",
        "  df[\"ask1vol_vs_mid\"] = df[\"ask1vol\"].div(df[\"mid\"])\n",
        "  df[\"ask2vol_vs_mid\"] = df[\"ask2vol\"].div(df[\"mid\"])\n",
        "\n",
        "  df[\"ask3_vs_mid\"] = df[\"ask3\"].div(df[\"mid\"])\n",
        "  df[\"ask4_vs_mid\"] = df[\"ask4\"].div(df[\"mid\"])\n",
        "  df[\"ask3vol_vs_mid\"] = df[\"ask3vol\"].div(df[\"mid\"])\n",
        "  df[\"ask4vol_vs_mid\"] = df[\"ask4vol\"].div(df[\"mid\"])\n",
        "  df[\"ask5_vs_mid\"] = df[\"ask5\"].div(df[\"mid\"])\n",
        "  df[\"ask5vol_vs_mid\"] = df[\"ask5vol\"].div(df[\"mid\"])\n",
        "\n",
        "  df[\"transact_div_bid1\"] = df[\"transacted_qty\"].div(df[\"bid1\"])\n",
        "  df[\"transact_div_bid1vol\"] = df[\"transacted_qty\"].div(df[\"bid1vol\"])\n",
        "  df[\"transact_div_bid2\"] = df[\"transacted_qty\"].div(df[\"bid2\"])\n",
        "  df[\"transact_div_bid2vol\"] = df[\"transacted_qty\"].div(df[\"bid2vol\"])\n",
        "  df[\"transact_div_bid3\"] = df[\"transacted_qty\"].div(df[\"bid3\"])\n",
        "  df[\"transact_div_bid3vol\"] = df[\"transacted_qty\"].div(df[\"bid3vol\"])\n",
        "  df[\"transact_div_bid4\"] = df[\"transacted_qty\"].div(df[\"bid4\"])\n",
        "  df[\"transact_div_bid4vol\"] = df[\"transacted_qty\"].div(df[\"bid4vol\"])\n",
        "  df[\"transact_div_bid5\"] = df[\"transacted_qty\"].div(df[\"bid5\"])\n",
        "  df[\"transact_div_bid5vol\"] = df[\"transacted_qty\"].div(df[\"bid5vol\"])\n",
        "\n",
        "  df[\"transact_div_ask1\"] = df[\"transacted_qty\"].div(df[\"ask1\"])\n",
        "  df[\"transact_div_ask1vol\"] = df[\"transacted_qty\"].div(df[\"ask1vol\"])\n",
        "  df[\"transact_div_ask2\"] = df[\"transacted_qty\"].div(df[\"ask2\"])\n",
        "  df[\"transact_div_ask2vol\"] = df[\"transacted_qty\"].div(df[\"ask2vol\"])\n",
        "  df[\"transact_div_ask3\"] = df[\"transacted_qty\"].div(df[\"ask3\"])\n",
        "  df[\"transact_div_ask3vol\"] = df[\"transacted_qty\"].div(df[\"ask3vol\"])\n",
        "  df[\"transact_div_ask4\"] = df[\"transacted_qty\"].div(df[\"ask4\"])\n",
        "  df[\"transact_div_ask4vol\"] = df[\"transacted_qty\"].div(df[\"ask4vol\"])\n",
        "  df[\"transact_div_ask5\"] = df[\"transacted_qty\"].div(df[\"ask5\"])\n",
        "  df[\"transact_div_ask5vol\"] = df[\"transacted_qty\"].div(df[\"ask5vol\"])\n",
        "\n",
        "  df[\"last_vs_mid\"] = df[\"last_price\"].div(df[\"mid\"])\n",
        "\n",
        "  df[\"sum_of_asks\"] = df[\"ask1\"].add(df[\"ask2\"]).add(df[\"ask3\"]).add(df[\"ask4\"]).add(df[\"ask5\"])\n",
        "  df[\"sum_of_bids\"] = df[\"bid1\"].add(df[\"bid2\"]).add(df[\"bid3\"]).add(df[\"bid4\"]).add(df[\"bid5\"])\n",
        "  df[\"total_volume_bids\"] = df[\"bid1vol\"].add(df[\"bid2vol\"]).add(df[\"bid3vol\"]).add(df[\"bid4vol\"]).add(df[\"bid5vol\"])\n",
        "  df[\"total_volume_asks\"] = df[\"ask1vol\"].add(df[\"ask2vol\"]).add(df[\"ask3vol\"]).add(df[\"ask4vol\"]).add(df[\"ask5vol\"])\n",
        "\n",
        "  df[\"total_ask_bid_difference\"] = df[\"sum_of_asks\"].sub(df[\"sum_of_bids\"])\n",
        "  df[\"total_volume_ask_bid_difference\"] = df[\"total_volume_asks\"].sub(df[\"total_volume_bids\"])\n",
        "\n",
        "  df[\"price_diff_bid_12\"] = df[\"bid1\"].sub(df[\"bid2\"])\n",
        "  df[\"price_diff_bid_13\"] = df[\"bid1\"].sub(df[\"bid3\"])\n",
        "  df[\"price_diff_bid_14\"] = df[\"bid1\"].sub(df[\"bid4\"])\n",
        "  df[\"price_diff_bid_15\"] = df[\"bid1\"].sub(df[\"bid5\"])\n",
        "\n",
        "  df[\"price_diff_bid_23\"] = df[\"bid2\"].sub(df[\"bid3\"])\n",
        "  df[\"price_diff_bid_24\"] = df[\"bid2\"].sub(df[\"bid4\"])\n",
        "  df[\"price_diff_bid_25\"] = df[\"bid2\"].sub(df[\"bid5\"])  \n",
        "  df[\"price_diff_bid_34\"] = df[\"bid3\"].sub(df[\"bid4\"])\n",
        "  df[\"price_diff_bid_35\"] = df[\"bid3\"].sub(df[\"bid5\"])   \n",
        "  df[\"price_diff_bid_45\"] = df[\"bid4\"].sub(df[\"bid5\"])\n",
        "\n",
        "  df[\"price_diff_ask_12\"] = df[\"ask2\"].sub(df[\"ask1\"])\n",
        "  df[\"price_diff_ask_13\"] = df[\"ask3\"].sub(df[\"ask1\"])\n",
        "  df[\"price_diff_ask_14\"] = df[\"ask4\"].sub(df[\"ask1\"])\n",
        "  df[\"price_diff_ask_15\"] = df[\"ask5\"].sub(df[\"ask1\"])\n",
        "\n",
        "  df[\"price_diff_ask_23\"] = df[\"ask3\"].sub(df[\"ask2\"])\n",
        "  df[\"price_diff_ask_24\"] = df[\"ask4\"].sub(df[\"ask2\"])\n",
        "  df[\"price_diff_ask_25\"] = df[\"ask5\"].sub(df[\"ask2\"])\n",
        "  df[\"price_diff_ask_34\"] = df[\"ask4\"].sub(df[\"ask3\"])\n",
        "  df[\"price_diff_ask_35\"] = df[\"ask5\"].sub(df[\"ask3\"])\n",
        "  df[\"price_diff_ask_45\"] = df[\"ask5\"].sub(df[\"ask4\"])\n",
        "\n",
        "  df[\"open_interest_vs_mid\"] = df[\"d_open_interest\"].div(df[\"mid\"])\n",
        "  df[\"open_interest_vs_last_price\"] = df[\"d_open_interest\"].div(df[\"last_price\"])\n",
        "  df[\"open_interest_vs_ask1\"] = df[\"d_open_interest\"].div(df[\"ask1\"])\n",
        "  df[\"open_interest_vs_bid1\"] = df[\"d_open_interest\"].div(df[\"bid1\"])\n",
        "  df[\"open_interest_vs_ask1vol\"] = df[\"d_open_interest\"].div(df[\"ask1vol\"])\n",
        "  df[\"open_interest_vs_bid1vol\"] = df[\"d_open_interest\"].div(df[\"bid1vol\"])\n",
        "  \n",
        "  df[\"open_interest_vs_ask2\"] = df[\"d_open_interest\"].div(df[\"ask2\"])\n",
        "  df[\"open_interest_vs_bid2\"] = df[\"d_open_interest\"].div(df[\"bid2\"])\n",
        "  df[\"open_interest_vs_ask2vol\"] = df[\"d_open_interest\"].div(df[\"ask2vol\"])\n",
        "  df[\"open_interest_vs_bid2vol\"] = df[\"d_open_interest\"].div(df[\"bid2vol\"])\n",
        "\n",
        "  df[\"open_interest_vs_ask3\"] = df[\"d_open_interest\"].div(df[\"ask3\"])\n",
        "  df[\"open_interest_vs_bid3\"] = df[\"d_open_interest\"].div(df[\"bid3\"])\n",
        "  df[\"open_interest_vs_ask3vol\"] = df[\"d_open_interest\"].div(df[\"ask3vol\"])\n",
        "  df[\"open_interest_vs_bid3vol\"] = df[\"d_open_interest\"].div(df[\"bid3vol\"])\n",
        "\n",
        "  df[\"open_interest_vs_ask4\"] = df[\"d_open_interest\"].div(df[\"ask4\"])\n",
        "  df[\"open_interest_vs_bid4\"] = df[\"d_open_interest\"].div(df[\"bid4\"])\n",
        "  df[\"open_interest_vs_ask4vol\"] = df[\"d_open_interest\"].div(df[\"ask4vol\"])\n",
        "  df[\"open_interest_vs_bid4vol\"] = df[\"d_open_interest\"].div(df[\"bid4vol\"])\n",
        "\n",
        "  df[\"open_interest_vs_ask5\"] = df[\"d_open_interest\"].div(df[\"ask5\"])\n",
        "  df[\"open_interest_vs_bid5\"] = df[\"d_open_interest\"].div(df[\"bid5\"])\n",
        "  df[\"open_interest_vs_ask5vol\"] = df[\"d_open_interest\"].div(df[\"ask5vol\"])\n",
        "  df[\"open_interest_vs_bid5vol\"] = df[\"d_open_interest\"].div(df[\"bid5vol\"])\n",
        "\n",
        "  # Remove columns\n",
        "  df_new = df.drop(columns=['id'])\n",
        "  # Replace NaN with 0\n",
        "  df_new = df_new.fillna(0)\n",
        "\n",
        "  return df_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzLNRP3BRspH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_processed = process_dataframe(train_df)\n",
        "test_df_processed = process_dataframe(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1gZAzo2lDhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_df_processed.drop(columns=['y'])\n",
        "y = train_df_processed['y']\n",
        "\n",
        "X_scaled = preprocessing.scale(X)\n",
        "\n",
        "train_df_scaled = pd.DataFrame(X_scaled)\n",
        "train_X = train_df_scaled[train_df_scaled.index % 5 != 0]\n",
        "val_X = train_df_scaled[train_df_scaled.index % 5 == 0]\n",
        "\n",
        "train_y = y[y.index % 5 != 0]\n",
        "val_y = y[y.index % 5 == 0]\n",
        "\n",
        "train_dataset = data_utils.TensorDataset(torch.tensor(train_X.values.astype(float)),\n",
        "                                         torch.tensor(train_y.values.astype(int)))\n",
        "\n",
        "val_dataset = data_utils.TensorDataset(torch.tensor(val_X.values.astype(float)),\n",
        "                                         torch.tensor(val_y.values.astype(int)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa3-F-jFnP9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = test_df_processed\n",
        "# Scale the X data\n",
        "test_x_scaled = preprocessing.scale(test_x)\n",
        "test_y = np.zeros(len(test_x))\n",
        "actual_test_dataset = data_utils.TensorDataset(torch.tensor(test_x_scaled), torch.tensor(test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPz271EBNMP5",
        "colab_type": "code",
        "outputId": "48cbad82-1fad-43ec-893d-f36c15fe2c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Graduated Network Design\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(156, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(32, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(16, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(8, 2),\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = data_utils.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "val_loader = data_utils.DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
        "actual_test_loader = data_utils.DataLoader(actual_test_dataset, batch_size=191859, shuffle=False)\n",
        "\n",
        "min_test_acc = 66.6\n",
        "max_epochs = 50\n",
        "prev_test_acc = 0\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    if prev_test_acc > min_test_acc:\n",
        "      print('Yay! test acc', prev_test_acc)\n",
        "      break\n",
        "\n",
        "    # First set to train\n",
        "    model.train()\n",
        "    print(f'Epoch {epoch+1}/50:')\n",
        "    train_correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data.float())\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            output = model(data.float())\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        test_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print('Train Loss: %.4f' % loss.item())\n",
        "    print('Train Accuracy: %d/%d (%.4f)' % (train_correct, \n",
        "                                            len(train_loader.dataset),\n",
        "                                            100. * train_correct /\n",
        "                                            len(train_loader.dataset)))\n",
        "    \n",
        "    print('Test Loss: %.4f' % test_loss)\n",
        "    print('Test Accuracy: %d/%d (%.4f)' % (test_correct, \n",
        "                                            len(val_loader.dataset),\n",
        "                                            100. * test_correct /\n",
        "                                            len(val_loader.dataset)))\n",
        "    prev_test_acc = 100. * test_correct / len(val_loader.dataset)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50:\n",
            "Train Loss: 0.6041\n",
            "Train Accuracy: 312803/473904 (66.0056)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78424/118476 (66.1940)\n",
            "\n",
            "Epoch 2/50:\n",
            "Train Loss: 0.6126\n",
            "Train Accuracy: 314013/473904 (66.2609)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78090/118476 (65.9121)\n",
            "\n",
            "Epoch 3/50:\n",
            "Train Loss: 0.6210\n",
            "Train Accuracy: 314354/473904 (66.3328)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78018/118476 (65.8513)\n",
            "\n",
            "Epoch 4/50:\n",
            "Train Loss: 0.5971\n",
            "Train Accuracy: 314626/473904 (66.3902)\n",
            "Test Loss: 0.0049\n",
            "Test Accuracy: 77845/118476 (65.7053)\n",
            "\n",
            "Epoch 5/50:\n",
            "Train Loss: 0.6333\n",
            "Train Accuracy: 314500/473904 (66.3637)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78191/118476 (65.9973)\n",
            "\n",
            "Epoch 6/50:\n",
            "Train Loss: 0.6296\n",
            "Train Accuracy: 314867/473904 (66.4411)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78124/118476 (65.9408)\n",
            "\n",
            "Epoch 7/50:\n",
            "Train Loss: 0.6042\n",
            "Train Accuracy: 314982/473904 (66.4654)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78137/118476 (65.9518)\n",
            "\n",
            "Epoch 8/50:\n",
            "Train Loss: 0.6071\n",
            "Train Accuracy: 315224/473904 (66.5164)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78324/118476 (66.1096)\n",
            "\n",
            "Epoch 9/50:\n",
            "Train Loss: 0.6060\n",
            "Train Accuracy: 315163/473904 (66.5036)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78566/118476 (66.3139)\n",
            "\n",
            "Epoch 10/50:\n",
            "Train Loss: 0.6209\n",
            "Train Accuracy: 315129/473904 (66.4964)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78066/118476 (65.8918)\n",
            "\n",
            "Epoch 11/50:\n",
            "Train Loss: 0.6069\n",
            "Train Accuracy: 315163/473904 (66.5036)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78485/118476 (66.2455)\n",
            "\n",
            "Epoch 12/50:\n",
            "Train Loss: 0.6180\n",
            "Train Accuracy: 315108/473904 (66.4919)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78626/118476 (66.3645)\n",
            "\n",
            "Epoch 13/50:\n",
            "Train Loss: 0.6218\n",
            "Train Accuracy: 315344/473904 (66.5417)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78617/118476 (66.3569)\n",
            "\n",
            "Epoch 14/50:\n",
            "Train Loss: 0.6003\n",
            "Train Accuracy: 315280/473904 (66.5282)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78898/118476 (66.5941)\n",
            "\n",
            "Epoch 15/50:\n",
            "Train Loss: 0.6039\n",
            "Train Accuracy: 315419/473904 (66.5576)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78853/118476 (66.5561)\n",
            "\n",
            "Epoch 16/50:\n",
            "Train Loss: 0.5961\n",
            "Train Accuracy: 315620/473904 (66.6000)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 78727/118476 (66.4497)\n",
            "\n",
            "Epoch 17/50:\n",
            "Train Loss: 0.5969\n",
            "Train Accuracy: 315688/473904 (66.6143)\n",
            "Test Loss: 0.0048\n",
            "Test Accuracy: 79019/118476 (66.6962)\n",
            "\n",
            "Yay! test acc 66.69620851480468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbXRfNmBOkPH",
        "colab_type": "code",
        "outputId": "ee3e4fb4-93f8-41b7-802b-6d55409a1d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "actual_test_loader = data_utils.DataLoader(actual_test_dataset, batch_size=191859, shuffle=False)\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "probabilities = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data, y in actual_test_loader:\n",
        "      output = model(data.float())\n",
        "      probs = F.softmax(output, dim=1).tolist()\n",
        "      probabilities += probs\n",
        "\n",
        "probabilities[:5:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.4668819308280945, 0.5331181287765503],\n",
              " [0.7761101126670837, 0.22388985753059387],\n",
              " [0.5967398881912231, 0.4032600522041321],\n",
              " [0.5725943446159363, 0.42740562558174133],\n",
              " [0.7197908759117126, 0.28020909428596497]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS7Eb7QBOpoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['Predicted'] = np.array(probabilities)[:,1]\n",
        "test_df[['id','Predicted']].to_csv(\"submission7.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJV3WUjhTj5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}